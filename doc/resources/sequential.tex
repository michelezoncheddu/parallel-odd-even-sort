\section{Sequential version}
The sequential version of the algorithm is simply based on a while-loop that goes on until there are no swaps in the two phases, that are called inside the loop's body.

\paragraph{Vectorization}
The main optimization that I made concerns the way in which the swaps are performed: a first naive version used the \texttt{std::swap} function, but since the loop of swaps was working over an array and without dependencies between different iterations, I exploited the loop vectorization, by swapping the elements through assignments with the ternary operator.

With the standard vectorization included with the flag \texttt{-O3}, the compiler is unaware of the hardware of the machine, so the code is vectorized using 128 bit vector registers. However, one of the improvements of the Xeon Phi Knights Landing (KNL) over its predecessors is the support to AVX-512 instructions (every core has also two vector units), and to make the compiler aware of the underlying architecture I used the flag \texttt{-march=native}, that recognizes the KNL platform and allows to vectorize with 512 bit vector registers.

In particular, I got advantages from the AVX-512F (Foundation) set, that extends the basic AXV instructions to 512 bit. Unfortunately, I didn't get any advantage from AVX-512PF set, that offers prefetch for gather/scatter operations, but most importantly the \texttt{PREFETCHWT1} operation, that prefetches data into level 2 cache (and higher) with intent to write, with respect to the first level cache misses (\texttt{T1} hint). I read the assembly code generated by the compiler and there was no sign of software prefetching. Probably the code is so simple and predictable that the hardware prefetcher does not need any software hint.
\bigbreak

Here are the completion time improvements with the vectorization (tested with 100K elements):
\begin{itemize}
    \item no vectorization: 30s
    \item 128 bit vector registers: 15.4s (1.95 times faster)
    \item 512 bit vector registers: 3.7s (8.11 times faster)
\end{itemize}

\paragraph{Thread pinning}
During the tests, I noticed that sometimes the thread was moved around the logical threads of the Xeon, causing cache invalidations and inconsistent performance on many different trials. Since the \texttt{pthread\_setaffinity\_np} function requires a native handle of the thread to pin, and there's no direct way to get this handle from the main thread in C++, I used a dirty trick that casts the thread id to a \texttt{std::thread::native\_handle\_type}. In this way I achieved more consistent results in testing.
